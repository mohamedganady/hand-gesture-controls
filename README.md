# ğŸ– Hand Gesture Controls (Mouse & Volume)

Control your **mouse cursor, clicks, and system volume** using **hand gestures** captured from your webcam.  
Built with **Python, OpenCV, and MediaPipe Tasks**. Optimized for **macOS**.

---

## ğŸ“– Project Description
This project enables touchless control of your **mouse (cursor movement and clicks)** and **system volume** using real-time **hand gestures**.  
It leverages computer vision to detect hand landmarks and translate them into actual operating system actions.

---

## ğŸ§© Requirements
- **Python 3.10+** (recommended: **3.11**)  
- **Webcam** (built-in or external)  
- **macOS recommended** (volume control via AppleScript)  
- **Git**

---

## ğŸ”½ Clone
```bash
git clone https://github.com/mohamedganady/hand-gesture-controls.git
cd hand-gesture-controls
```

---

## ğŸ§ª Create & Activate Virtual Environment

**macOS / Linux**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**Windows (PowerShell)**
```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
```

---

## ğŸ“¦ Install Dependencies
```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run
```bash
python main.py
```
- Press **ESC** to exit.  
- On the first run, the MediaPipe hand model will be downloaded automatically if it is not already present.

---

## ğŸ– Gesture Guide
| Gesture | Action |
|--------|--------|
| Move index finger | Move mouse cursor |
| Pinch (index + middle) | Click |
| Open hand âœ‹ | Enable volume control |
| Closed hand âœŠ | Disable volume control |
| Thumb â†” Index distance | Increase / Decrease volume |

---

## ğŸ“ Project Structure
```
hand-gesture-controls/
â”œâ”€ main.py               # Full system: mouse + click + volume + on-screen UI
â”œâ”€ mouse_cursor.py      # Cursor movement logic
â”œâ”€ clickUsingPinch.py   # Pinch-click gesture testing
â”œâ”€ count.py             # Finger counting experiments
â”œâ”€ test.py              # MediaPipe / environment checks
â”œâ”€ requirements.txt     # Project dependencies
â””â”€ README.md            # Documentation
```

---

## ğŸ§  How It Works
1) **Capture** video frames using OpenCV  
2) **Detect** hand landmarks using MediaPipe Tasks  
3) **Map** landmarks to:
   - Cursor position (index fingertip)
   - Click action (pinch gesture)
   - Volume level (thumbâ€“index distance)  
4) **Smooth and apply** actions while rendering a live UI overlay

---

## ğŸ›  Troubleshooting

**Camera not working / black screen**
- Close other apps using the camera (Zoom, Teams, browsers)
- Try another camera index in code:
```python
cap = cv2.VideoCapture(1)
```
- Restart the terminal

**Volume does not change on macOS**
```bash
osascript -e 'set volume output volume 50'
```
If this does not change the volume, check macOS automation permissions.

**Cursor is shaking or too sensitive**
- Increase smoothing values in `main.py`
- Improve lighting conditions
- Keep your hand centered and steady

---

## ğŸ§ª Use-Cases
- Touchless control for presentations  
- Accessibility tools  
- HCI / Computer Vision demonstrations  
- Robotics & AI education  
- Smart workspaces  

---

## ğŸ—º Roadmap
- Windows support using `pycaw`  
- Left / Right click gestures  
- Calibration & sensitivity UI  
- Multi-hand support  
- Custom gesture mapping  

---

## ğŸ™ Acknowledgements
- Google **MediaPipe**  
- **OpenCV** community  
- Python open-source ecosystem  

---

## ğŸ‘¨â€ğŸ’» Author
**Mohamed Ganady**  
Robotics & AI Instructor | Embedded Systems Developer  
GitHub: https://github.com/mohamedganady  

---

## ğŸ“ License
MIT License â€” free to use and modify with attribution.
